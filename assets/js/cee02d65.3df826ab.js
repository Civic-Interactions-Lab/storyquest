"use strict";(self.webpackChunkcreate_project_docs=self.webpackChunkcreate_project_docs||[]).push([[7629],{78655:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>c,default:()=>p,frontMatter:()=>o,metadata:()=>r,toc:()=>a});var s=t(74848),i=t(28453);const o={sidebar_position:5},c="TextToSpeechAACButtons Component",r={id:"api-specification/Frontend Documentation/Components/text-to-speech-aac",title:"TextToSpeechAACButtons Component",description:"Description:",source:"@site/docs/api-specification/Frontend Documentation/Components/text-to-speech-aac.md",sourceDirName:"api-specification/Frontend Documentation/Components",slug:"/api-specification/Frontend Documentation/Components/text-to-speech-aac",permalink:"/storyquest/docs/api-specification/Frontend Documentation/Components/text-to-speech-aac",draft:!1,unlisted:!1,tags:[],version:"current",lastUpdatedBy:"Ian Applebaum",sidebarPosition:5,frontMatter:{sidebar_position:5},sidebar:"docsSidebar",previous:{title:"Text-to-Speech Component",permalink:"/storyquest/docs/api-specification/Frontend Documentation/Components/text-to-speech"},next:{title:"Hooks",permalink:"/storyquest/docs/api-specification/Frontend Documentation/Components/hooks"}},l={},a=[{value:"Props",id:"props",level:2},{value:"Behavior",id:"behavior",level:2},{value:"UI Elements",id:"ui-elements",level:2},{value:"Accessibility",id:"accessibility",level:2},{value:"Usage Example",id:"usage-example",level:2}];function d(e){const n={br:"br",code:"code",h1:"h1",h2:"h2",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.h1,{id:"texttospeechaacbuttons-component",children:"TextToSpeechAACButtons Component"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Description:"}),(0,s.jsx)(n.br,{}),"\n",(0,s.jsx)(n.code,{children:"TextToSpeechAACButtons"}),": This component provides basic text-to-speech functionality using the Web Speech API. It includes accessible Play and Stop buttons, allowing users to listen to the provided text. The component is optimized for AAC (Augmentative and Alternative Communication) scenarios and supports notification via a callback when speech ends."]}),"\n",(0,s.jsx)(n.h2,{id:"props",children:"Props"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsxs)(n.strong,{children:[(0,s.jsx)(n.code,{children:"text"})," (required):"]})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Type: ",(0,s.jsx)(n.code,{children:"string"})]}),"\n",(0,s.jsx)(n.li,{children:"Description: The string to be read aloud via text-to-speech."}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsxs)(n.strong,{children:[(0,s.jsx)(n.code,{children:"onSpeechEnd"})," (optional):"]})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Type: ",(0,s.jsx)(n.code,{children:"() => void"})]}),"\n",(0,s.jsx)(n.li,{children:"Description: A callback function that is triggered when the speech ends."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"behavior",children:"Behavior"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Initializes a ",(0,s.jsx)(n.code,{children:"SpeechSynthesisUtterance"})," each time the ",(0,s.jsx)(n.code,{children:"text"})," prop changes."]}),"\n",(0,s.jsxs)(n.li,{children:["Listens for ",(0,s.jsx)(n.code,{children:"end"})," and ",(0,s.jsx)(n.code,{children:"pause"})," events to manage playback state and trigger optional callbacks."]}),"\n",(0,s.jsxs)(n.li,{children:["Cleans up speech events and cancels playback when the component unmounts or when ",(0,s.jsx)(n.code,{children:"text"})," updates."]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"ui-elements",children:"UI Elements"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Play Button"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Starts or resumes speech playback."}),"\n",(0,s.jsx)(n.li,{children:"Cancels any previously queued or ongoing speech before starting new playback."}),"\n",(0,s.jsx)(n.li,{children:'Aria label dynamically updates to "Play speech" or "Resume speech" based on state.'}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Stop Button"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Cancels all speech and resets the state."}),"\n",(0,s.jsxs)(n.li,{children:["Disabled if there is no speech queued (",(0,s.jsx)(n.code,{children:"utterance"})," is null)."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"accessibility",children:"Accessibility"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Buttons are labeled using ",(0,s.jsx)(n.code,{children:"aria-label"})," attributes to support screen reader usage."]}),"\n",(0,s.jsx)(n.li,{children:"Ensures speech state is accurately reflected through button states and interactivity."}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"usage-example",children:"Usage Example"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-tsx",children:'import TextToSpeechAACButtons from \'./TextToSpeechAACButtons\';\n\nconst Example = () => {\n  const handleSpeechEnd = () => {\n    console.log("Speech finished.");\n  };\n\n  return (\n    <TextToSpeechAACButtons\n      text="Welcome to the accessible text-to-speech demo."\n      onSpeechEnd={handleSpeechEnd}\n    />\n  );\n};\n'})})]})}function p(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},28453:(e,n,t)=>{t.d(n,{R:()=>c,x:()=>r});var s=t(96540);const i={},o=s.createContext(i);function c(e){const n=s.useContext(o);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:c(e.components),s.createElement(o.Provider,{value:n},e.children)}}}]);